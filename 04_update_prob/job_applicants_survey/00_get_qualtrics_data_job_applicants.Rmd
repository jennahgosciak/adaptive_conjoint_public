---
title: "Process Qualtrics Data and Treatment Assignment Updating for Political Candidates Survey"
output: rmarkdown::github_document
date: "2023-11-07"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Setup Data Using Qualtrics API

* Load data directly from Qualtrics
* Can store API Key and credentials in `.renviron`

```{r, load packages, message=F, warning=F}
library(tidyverse)
library(qualtRics)
library(magrittr)
library(assertr)
library(RColorBrewer)

knitr::opts_chunk$set(cache.extra = 2023)

source("../_functions/data_cleaning.R")
config <- config::get()

# load log of probabilities
probabilities <- read_csv("../../02_output/probabilities_job_applicants.csv")
probabilities
```

```{r, setup qualtrics}
url <- str_glue("https://{config$datacenter_id}.qualtrics.com")
survey_name <- "Job Applicants"

# can comment out after running once
# qualtrics_api_credentials(api_key = config$api_token,
#                           base_url = url,
#                           install = TRUE,
#                           overwrite=T)

df <- load_qualtrics(survey_name)

df %>%
  nrow()
```

```{r}
# drop test data
df <- df %>%
  mutate(StartDate_clean = ymd_hms(StartDate)) %>%
  verify(is.na(StartDate_clean) == is.na(StartDate)) %>%
  filter(StartDate_clean >= ymd_hms("2024-02-25-18-00-00"))

df %>%
  nrow()
```

```{r}
# calculate average per minute
df %>% 
  mutate(min = minute(StartDate_clean),
         hr = hour(StartDate_clean),
         date = date(StartDate_clean),
         min_10 = cut(min, breaks=c(0,10, 20, 30, 40, 50, 60))) %>% 
  group_by(min_10, hr, date) %>% 
  summarize(total = n()) %>% 
  ungroup() %>% 
  #filter(total >= 3) %>% 
  summarize(avg_per_10min = mean(total),
            med_per_10min = quantile(total, 0.5),
            min_per_10min = min(total),
            max_per_10min = max(total))
```


```{r}
# average finished rate
mean(df$Finished)

# average time to complete
mean(df$`Duration (in seconds)`)

# compare amount of time spent
df %>%
  summarize(across(c(`Duration (in seconds)`),
    .fns = lst(
      mean = ~ mean(.) / 60,
      min = ~ min(.) / 60,
      max = ~ max(.) / 60,
      median = ~ median(.) / 60
    )
  ))
```
## Create Batch ID variable
```{r}
# hardcoding this because it should not be changing each time
# we should only update it as we increase batches

# check max date times on each day
df %>%
  mutate(date = date(StartDate_clean)) %>%
  group_by(date) %>%
  summarize(max_date_time = max(StartDate_clean))

df <- df %>%
  # drop data collected incorrectly
  mutate(
    batch_id = case_when(
      # NEED TO CHANGE
      StartDate_clean <= ymd_hms("2024-02-25-20-00-00") ~ 0,
      StartDate_clean <= ymd_hms("2024-02-26-00-00-00") ~ 1,
      StartDate_clean <= ymd_hms("2024-02-26-12-40-00") ~ 2,
      StartDate_clean <= ymd_hms("2024-02-26-13-30-00") ~ 3,
      StartDate_clean <= ymd_hms("2024-02-26-14-50-00") ~ 4,
      StartDate_clean <= ymd_hms("2024-02-26-18-50-00") ~ 5,
      StartDate_clean <= ymd_hms("2024-02-26-21-20-00") ~ 6,
      StartDate_clean <= ymd_hms("2024-02-26-22-35-00") ~ 7,
      StartDate_clean <= ymd_hms("2024-02-27-11-50-00") ~ 8,
      StartDate_clean <= ymd_hms("2024-02-27-12-40-00") ~ 9,
      StartDate_clean <= ymd_hms("2024-02-27-13-40-00") ~ 10,
      StartDate_clean <= ymd_hms("2024-02-27-14-40-00") ~ 11,
      StartDate_clean <= ymd_hms("2024-02-27-15-30-00") ~ 12,
      StartDate_clean <= ymd_hms("2024-02-29-14-10-00") ~ 13,
      StartDate_clean <= ymd_hms("2024-03-01-11-20-00") ~ 14,
      StartDate_clean <= ymd_hms("2024-03-01-12-50-00") ~ 15,
      StartDate_clean <= ymd_hms("2024-03-01-14-10-00") ~ 16,
      StartDate_clean <= ymd_hms("2024-03-01-15-40-00") ~ 17,
      StartDate_clean <= ymd_hms("2024-03-01-16-50-00") ~ 18,
      StartDate_clean <= ymd_hms("2024-03-01-20-10-00") ~ 19,
      StartDate_clean <= ymd_hms("2024-03-01-22-10-00") ~ 20,
      StartDate_clean <= ymd_hms("2024-03-06-11-30-00") ~ 1,
      StartDate_clean <= ymd_hms("2024-03-06-16-10-00") ~ 2,
      StartDate_clean <= ymd_hms("2024-03-07-12-50-00") ~ 3,
      StartDate_clean <= ymd_hms("2024-03-07-17-10-00") ~ 4,
      StartDate_clean <= ymd_hms("2024-03-07-19-50-00") ~ 5,
      StartDate_clean <= ymd_hms("2024-03-08-14-20-00") ~ 6,
      StartDate_clean <= ymd_hms("2024-03-08-17-20-00") ~ 7,
      StartDate_clean <= ymd_hms("2024-03-11-11-20-00") ~ 8,
      StartDate_clean <= ymd_hms("2024-03-11-13-20-00") ~ 9,
      StartDate_clean <= ymd_hms("2024-03-11-17-40-00") ~ 10,
      StartDate_clean <= ymd_hms("2024-03-11-20-10-00") ~ 11,
      StartDate_clean <= ymd_hms("2024-03-11-23-10-00") ~ 12,
      StartDate_clean <= ymd_hms("2024-03-12-08-00-00") ~ 13,
      StartDate_clean <= ymd_hms("2024-03-12-12-58-00") ~ 14,
      StartDate_clean <= ymd_hms("2024-03-12-15-50-00") ~ 15,
      StartDate_clean <= ymd_hms("2024-03-12-20-50-00") ~ 16,
      StartDate_clean <= ymd_hms("2024-03-13-00-50-00") ~ 17,
      StartDate_clean <= ymd_hms("2024-03-13-09-20-00") ~ 18,
      StartDate_clean <= ymd_hms("2024-03-13-12-40-00") ~ 19,
      StartDate_clean <= ymd_hms("2024-03-13-15-55-00") ~ 20,
      TRUE ~ NA_integer_
    ),
    batch_type = case_when(
      batch_id == 0 ~ "Warmup",
      StartDate_clean <= ymd_hms("2024-03-01-22-10-00") ~ "Iterative Batch Phase: Max",
      StartDate_clean <= ymd_hms("2024-03-13-15-55-00") ~ "Iterative Batch Phase: Min",
      TRUE ~ NA_character_
    )
  ) %>%
  verify(!is.na(batch_id)) %>%
  verify(!is.na(batch_type))

df %>%
  group_by(batch_type, batch_id) %>%
  summarize(n = n())
```

## Survey Validation

```{r, check id}
# check ID uniquely identifies rows in data
if (length(unique(df$`Prolific ID Q`)) != nrow(df)) {
  warning("ID is not unique")
}

if (!all(unique(df$Status) == "IP Address")) {
  warning("Test/spam data included in the analysis file")
  print(str_glue("Number of observations in data: {nrow(df)}"))
  print(str_glue("Status values in data: {str_c(unique(df$Status), collapse=', ')}"))
  df <- df %>%
    filter(Status == "IP Address")
  print(str_glue("Number of observations left in data: {nrow(df)}"))
}
```

```{r, check embed data}
# check embedded data variables match probabilities for all iterative batches
df %>%
  check_pi_vars(probabilities, 3)
```

```{r}
# check distinct probabilities based on embedded data
df %>%
  select(batch_type, batch_id, str_c("pi", 1:3)) %>%
  distinct()
```

```{r}
# check consent means their responses are missing
df %>%
  filter(Consent == "I do not consent to participate") %>%
  select(Consent, `Duration (in seconds)`, Finished, batch_id, batch_type)

df <- df %>%
  check_consent()
```

```{r}
# check that all completed
df %>%
  filter(Finished != TRUE) %>%
  select(StartDate_clean, EndDate, `Duration (in seconds)`, Finished, Consent, PreScreen_Q1:QD5)

df <- df %>%
  check_completion()
```


```{r}
df <- df %>%
  check_location_screen()

df <- df %>%
  check_hiring_screen()
```

```{r}
# visually assessing why these respondents failed the commitment check
df %>%
  filter(Commitment_Q1 != "Yes, I will") %>%
  select(Commitment_Q1, Commitment_Q2, `Duration (in seconds)`, Finished, batch_id, batch_type)


df %>%
  filter(str_to_lower(Commitment_Q2) %>% 
               str_replace_all('\\.', '') != "purple") %>%
  select(Commitment_Q1, Commitment_Q2, `Duration (in seconds)`, Finished, batch_id, batch_type)

df <- df %>%
  check_commitment()
```

```{r}
# check ID is unique again
if (length(unique(df$`Prolific ID Q`)) != nrow(df)) {
  warning("ID is not unique")
  print(str_glue("Number of rows in data: {nrow(df)}"))
  df <- df %>%
    group_by(`Prolific ID Q`) %>%
    arrange(`Prolific ID Q`, StartDate_clean) %>%
    mutate(flag_first_obs = if_else(row_number() == 1, 1, 0)) %>%
    ungroup()

  df %>%
    group_by(`Prolific ID Q`) %>%
    mutate(n = n()) %>%
    arrange(desc(n), StartDate_clean) %>%
    ungroup() %>%
    select(PROLIFIC_PID, `Prolific ID Q`, n, StartDate_clean, EndDate, flag_first_obs, `Duration (in seconds)`, Finished, batch_id, batch_type) %>%
    print()

  df <- df %>%
    filter(flag_first_obs == 1)

  print(str_glue("Number of rows in data after dropping duplicate ID: {nrow(df)}"))
}

stopifnot(length(unique(df$`Prolific ID Q`)) == nrow(df))
```

## Create Context and Context Label Variables

```{r}
# create context variable
df <- df %>%
  mutate(across(str_c("Q", 1:8), .fns = lst(orig = ~.))) %>%
  create_context_var_jobs() %>%
  verify(!is.na(context)) %>%
  verify(!is.na(context_label))

df %>%
  group_by(batch_type, context, context_label) %>%
  summarize(n = n())

df %>%
  group_by(batch_type, batch_id) %>%
  summarize(n = n())
```

```{r}
df %>%
  group_by(context, batch_type, batch_id) %>%
  filter(batch_type %in% c("Warmup", "Iterative Batch Phase: Max")) %>%
  summarize(n = n()) %>%
  group_by(batch_type, batch_id) %>%
  mutate(n = n / sum(n)) %>%
  ggplot(aes(context, n)) +
  geom_col() +
  theme_classic() +
  facet_wrap(~batch_id) +
  labs(
    title = "Sample Sizes in Iterative Batch Phase: Max",
    y = "Share of total"
  )

df %>%
  group_by(context, batch_type, batch_id) %>%
  filter(batch_type %in% c("Warmup", "Iterative Batch Phase: Min")) %>%
  summarize(n = n()) %>%
  group_by(batch_type, batch_id) %>%
  mutate(n = n / sum(n)) %>%
  ggplot(aes(context, n)) +
  geom_col() +
  theme_classic() +
  facet_wrap(~batch_id) +
  labs(
    title = "Sample Sizes in Iterative Batch Phase: Min",
    y = "Share of total"
  )
```

```{r}
df %>%
  group_by(context, batch_type, batch_id) %>%
  filter(batch_type %in% c("Warmup", "Iterative Batch Phase: Max")) %>%
  summarize(n = n()) %>%
  group_by(batch_id, batch_type) %>%
  arrange(context) %>%
  mutate(n = cumsum(n) / sum(n)) %>%
  ggplot(aes(context, n)) +
  geom_col() +
  theme_classic() +
  facet_wrap(~batch_id) +
  labs(title = "Cumulative Sample Sizes in Iterative Batch Phase: Max")

df %>%
  group_by(context, batch_type, batch_id) %>%
  filter(batch_type %in% c("Warmup", "Iterative Batch Phase: Min")) %>%
  summarize(n = n()) %>%
  group_by(batch_id, batch_type) %>%
  arrange(context) %>%
  mutate(n = cumsum(n) / sum(n)) %>%
  ggplot(aes(context, n)) +
  geom_col() +
  theme_classic() +
  facet_wrap(~batch_id) +
  labs(title = "Cumulative Sample Sizes in Iterative Batch Phase: Min")
```


```{r}
df %>%
  filter(batch_type %in% c("Warmup", "Iterative Batch Phase: Max")) %>%
  group_by(batch_id, batch_type) %>%
  select(str_c("pi", 1:3)) %>%
  distinct() %>%
  pivot_longer(-c(batch_id, batch_type)) %>%
  mutate(context = str_replace_all(name, "pi", "")) %>%
  ggplot(aes(context, value)) +
  geom_col() +
  theme_classic() +
  facet_wrap(~batch_id)

df %>%
  filter(batch_type %in% c("Warmup", "Iterative Batch Phase: Min")) %>%
  group_by(batch_id, batch_type) %>%
  select(str_c("pi", 1:3)) %>%
  distinct() %>%
  pivot_longer(-c(batch_id, batch_type)) %>%
  mutate(context = str_replace_all(name, "pi", "")) %>%
  ggplot(aes(context, value)) +
  geom_col() +
  theme_classic() +
  facet_wrap(~batch_id) +
  labs(
    title = "CDF for Iterative Batch Phase: Min",
    y = "Cumulative Probability"
  )
```
```{r}
# check randomness of question ordering
# plot counts by question order
df %>%
  select(str_c("Q", 1:8)) %>%
  pivot_longer(everything()) %>%
  filter(value == "Candidate 1" | value == "Candidate 2") %>%
  mutate(order_val = as.numeric(str_replace_all(name, "Q", ""))) %>%
  ggplot() +
  geom_histogram(aes(order_val)) +
  theme_classic() +
  labs(x = "Order", y = "Number of responses")
```

## Clean Qualtrics Data

```{r}
df_clean <- create_outcome_var_jobs(df)

# each question number is the random ordering of the context attributes
df_clean %>%
  select(chose_mother, str_c("Q", 1:8), context) %>%
  verify(!is.na(chose_mother))

df_clean %>%
  group_by(context, context_label) %>%
  summarize(
    n = n(),
    chose_mother_total = sum(chose_mother),
    chose_nonmother_total = sum(chose_mother == 0)
  ) %>%
  mutate(diff = abs(chose_mother_total - chose_nonmother_total))

df_clean %>%
  group_by(batch_id, batch_type, context, context_label) %>%
  summarize(
    n = n(),
    chose_mother_total = sum(chose_mother),
    chose_nonmother_total = sum(chose_mother == 0)
  ) %>%
  mutate(diff = abs(chose_mother_total - chose_nonmother_total))
```


```{r, response breakdown}
# identify context desc
df_clean %>%
  select(context, context_label, starts_with("name"), starts_with("education")) %>%
  distinct() %>%
  arrange(context)
```

```{r, attention check}
# check manipulation questions
df_attention_check <- df_clean %>%
  mutate(
    candidate_mother = if_else(rnum_mother <= 0.5, "Candidate 2", "Candidate 1"),
    manipulation_check_missing = rowSums(select(., starts_with("Manipulation_Q1_")) %>%
      is.na())
  ) %>%
  mutate(
    pass_attention_check = case_when(
      (rnum_mother <= 0.5) &
        (Manipulation_Q1_2 == "Candidate 2") &
        # only when they've selected one response, i.e. missing = 2
        (manipulation_check_missing == 2) ~ 1,
      (rnum_mother > 0.5) &
        (Manipulation_Q1_1 == "Candidate 1") &
        # only when they've selected one response, i.e. missing = 2
        (manipulation_check_missing == 2) ~ 1,
      TRUE ~ 0
    ),
    pass_attention_check_any = case_when(
      (rnum_mother <= 0.5) &
        (Manipulation_Q1_2 == "Candidate 2") ~ 1,
      (rnum_mother > 0.5) &
        (Manipulation_Q1_1 == "Candidate 1") ~ 1,
      TRUE ~ 0
    ),
    unsure_attention_check = if_else(Manipulation_Q1_3 == "Not sure" & !is.na(Manipulation_Q1_3), 1, 0)
  )

df_attention_check %>%
  summarize(
    per_pass_attention_check = mean(pass_attention_check),
    per_pass_attention_check_any = mean(pass_attention_check_any),
    per_unsure = mean(unsure_attention_check)
  )

df_attention_check %>%
  group_by(batch_id, batch_type) %>%
  summarize(
    per_pass_attention_check = mean(pass_attention_check),
    per_pass_attention_check_any = mean(pass_attention_check_any),
    per_unsure = mean(unsure_attention_check)
  )

df_attention_check %>%
  mutate(candidate_mother = if_else(rnum_mother <= 0.5, "Candidate 2", "Candidate 1")) %>%
  select(
    rnum_mother, candidate_mother, pass_attention_check, chose_mother, str_c("Q", 1:8, "_orig"),
    starts_with("volunteer"), starts_with("Manipulation_Q1_")
  )

df_attention_check %>%
  mutate(candidate_mother = if_else(rnum_mother <= 0.5, "Candidate 2", "Candidate 1")) %>%
  select(
    rnum_mother, candidate_mother, pass_attention_check, chose_mother, starts_with("Manipulation_Q1_"),
    manipulation_check_missing, starts_with("volunteer")
  )
```

```{r, demog}
df_clean %>% 
  # checking for alphabetic characters
  filter(str_detect(QD2_1_TEXT, '[:alpha:]'))

df_clean <- df_clean %>%
  mutate(QD2_1_TEXT = if_else(QD2_1_TEXT %in% c('3e6', '3p'), NA_character_, QD2_1_TEXT),
         age = as.numeric(QD2_1_TEXT)) %>% 
  verify(is.na(QD2_1_TEXT) == is.na(age)) %>%
  #rename(age = QD2_1_TEXT) %>%
  mutate(
    hispanic = if_else(QD4 == "Yes", TRUE, FALSE),
    female = if_else(QD5 == "Female", TRUE, FALSE)
  ) %>%
  mutate(across(starts_with("QD3_"), .fns = lst(race_num = ~ if_else(!is.na(.), 1, 0)))) %>%
  mutate(
    race_count = rowSums(select(., ends_with("race_num"))),
    race = case_when(
      race_count > 1 ~ "Multiracial",
      !is.na(QD3_1) ~ "American Indian or Alaskan Native",
      !is.na(QD3_2) ~ "Asian",
      !is.na(QD3_3) ~ "Black or African American",
      !is.na(QD3_4) ~ "Native Hawaiian",
      !is.na(QD3_5) ~ "White",
      !is.na(QD3_6) ~ "Other",
      !is.na(QD3_7) ~ "Prefer not to disclose"
    )
  ) %>%
  verify(!is.na(race))

df_clean %>%
  group_by(race) %>%
  summarize(n = n()) %>%
  ungroup() %>%
  mutate(per = n / sum(n)) %>%
  arrange(desc(per))

df_clean %>%
  ggplot(aes(age)) +
  geom_histogram()

df_clean %>%
  group_by(female) %>%
  summarize(count = n())

df_clean %>%
  summarize(
    count_hispanic = sum(hispanic),
    per_hispanic = mean(hispanic)
  )
```

## Clean Data Validation

```{r}
# check every respondent has exactly one non-missing value
check_allmissing <- df_clean %>%
  select(str_c("Q", 1:8)) %>%
  mutate(across(everything(), ~ as.character(.))) %>%
  is.na() %>%
  rowSums(na.rm = T) %>%
  equals(8) %>%
  any()

if (check_allmissing == TRUE) {
  warning("Some rows are missing outcome responses\n")
}

# check row total is not more than 1
# 0 if selected the older candidate
check_rowtotal <- df_clean %>%
  select(str_c("Q", 1:8)) %>%
  rowSums(na.rm = T) %>%
  is_weakly_less_than(1) %>%
  all()

if (check_rowtotal == FALSE) {
  warning("Total of outcome responses is more than 1\n")
}
```

```{r}
# create ID with a random ordering
df_clean <- df_clean %>%
  mutate(rand_sort = runif(nrow(df_clean))) %>%
  arrange(batch_id, rand_sort) %>%
  mutate(unique_id = row_number()) %>%
  select(-rand_sort)
```


```{r}
df_clean %>%
  select(unique_id, context, context_label, batch_id, batch_type, chose_mother, race, age, female, hispanic) %>%
  saveRDS("../../02_output/job_applicants_data_clean.RDS")

df_clean %>%
  select(unique_id, context, context_label, batch_id, batch_type, chose_mother, race, age, female, hispanic) %>%
  write_csv("../../02_output/job_applicants_data_clean.csv")
```




