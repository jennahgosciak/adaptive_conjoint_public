---
title: "Process Qualtrics Data, Treatment Assignment Updating"
output: rmarkdown::github_document
date: "2023-11-07"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Setup Data Using Qualtrics API

* Load data directly from Qualtrics
* Can store API Key and credentials in `.renviron`

```{r, load packages, message=F, warning=F}
library(tidyverse)
library(qualtRics)
library(magrittr)
library(assertr)
library(RColorBrewer)

knitr::opts_chunk$set(cache.extra = 2023)

source("./_functions/data_cleaning.R")
source("./_functions/experiment_functions.R")
source("./_functions/plotting_functions.R")
source("./_functions/populate_probs.R")
```

```{r, setup qualtrics}
config <- config::get()
url <- str_glue("https://{config$datacenter_id}.qualtrics.com")

# qualtrics_api_credentials(api_key = config$api_key,
#                           base_url = url,
#                           install = TRUE,
#                           overwrite=T)


df <- load_qualtrics("Political Candidates")
df %>%
  head()
```

## Survey Validation

```{r}
df %>%
  distinct(Status)

# filter for test data
# replace with real data when running hte survey
df <- df %>%
  filter_test_data()

# check consent means their responses are missing
df %>%
  check_consent()

# check that all completed
df %>%
  check_completion()

df %>%
  # note: question was different prior to 11/06
  filter(StartDate >= lubridate::ymd("2023-11-06")) %>%
  check_location_screen()
```

```{r}
# create profile variable
df <- df %>%
  create_profile_var()

df %>%
  ggplot(aes(profile)) +
  geom_histogram() +
  theme_classic()
```

## Clean Qualtrics Data
```{r}
df_clean <- clean_qualtrics_data(df)

# each question number is the random ordering of the context attributes
df_clean %>%
  select(candidate_response, str_c("Q", 1:8), profile) %>%
  verify(!is.na(candidate_response))
```

## Clean Data Validation

```{r}
# check every respondent has exactly one non-missing value
df_clean %>%
  select(str_c("Q", 1:8)) %>%
  mutate(across(everything(), ~ as.character(.))) %>%
  is.na() %>%
  rowSums(na.rm = T)

# check row total is not more than 1
# 0 if selected the older candidate
df_clean %>%
  select(str_c("Q", 1:8)) %>%
  rowSums(na.rm = T) %>%
  is_weakly_less_than(1) %>%
  all() %>%
  stopifnot()
```

## Create fake data

```{r, setup fake data}
# batch size is the size of the batches (here = 100)
batch_size <- 100

# probabilities of selecting younger candidate
profile_prob <- c(0.9, 0.5, 0.3, 0.5, 0.4, 0.3, 0.5, 0.44)
pi <- cumsum(rep(0.125, 8)) # treatment assignment probabilities (CDF)
```

```{r}
df_fake <- create_fake_data(pi, profile_prob, batch_size)
df_fake
```

### Examine fake data

* Check distribution of profiles overall and by batch

```{r}
df_fake %>%
  ggplot(aes(profile)) +
  geom_histogram() +
  theme_classic()

df_fake %>%
  group_by(profile) %>%
  summarize(mean = mean(candidate_response)) %>%
  ggplot(aes(profile, mean)) +
  geom_col() +
  theme_classic()

df_fake %>%
  # share of respondents who select
  # the younger candidate
  group_by(profile) %>%
  summarize(
    mean = mean(candidate_response),
    total = sum(candidate_response)
  )
```

# Update treatment probabilities

```{r, global params}
# define with comments
num_profiles <- 8 # number of profiles
num_sim <- 1000 # number of simulations for Monte Carlo simulation
eps <- 0.1 # for epsilon greedy alg

N <- 4500 # total number of observations
num_batches <- N / batch_size # total number of batches
pi_init <- cumsum(rep(0.125, 8)) # initial pi cdf
```


```{r}
# generate pi on fake data
pi_ts_fake <- run_ts(batch_size, num_profiles, pi_init, fake_data = T)$pi
pi_ts_fake
```


```{r, message=F, warning=T}
# generate pi on real data
pi_ts <- run_ts(batch_size, num_profiles, pi_init, fake_data = F)$pi
pi_ts
```

```{r}
# init parameters
pi_list <- lst(rep(0.125, num_profiles))
num_outcome1 <- integer(num_profiles) # vector for each arm
num_outcome0 <- integer(num_profiles)

# generate pi on fake data
for (i in 1:num_batches) {
  output <- c(run_ts(batch_size, num_profiles, pi_list[[i]], num_outcome1, num_outcome0, fake_data = T, cdf = F))
  pi_list[i + 1] <- lst(output$pi)
  num_outcome1 <- output$num_outcome1
  num_outcome0 <- output$num_outcome0
}

tibble(
  "pi" = map(1:num_batches, ~ map(pi_list, ~ as.numeric(.))[[.]]),
  "arm" = map(1:num_batches, ~ c(1:8))
) %>%
  mutate(id = row_number()) %>%
  unnest(cols = c(pi, arm)) %>%
  mutate(arm_text = str_c("Context Profile", arm)) %>%
  ggplot(aes(id, pi, color = arm_text)) +
  geom_line() +
  # facet_wrap(~arm_text) +
  theme_classic() +
  labs(
    title = "Thompson Sampling Treatment Assignments Over Time by Context Arm",
    x = "Time",
    y = "Probability of being the most discriminatory context",
    color = ""
  ) +
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.2))

ggsave("treatment_assignment_prob.png")
```



